\section{Related work}

There are many systems commanding or communicating naturally with robots as well as creating programming
languages for robots usable by non-programmers, starting with the seminal work in SHRDLU~\cite{shrdlu},
and continuing over the years~\cite{kollarDialog,thomasonDialog,roboFlow}.
% We believe that natural language---if done right---is the most promising interface with robots (or machines in general).
% \todo[inline]{ED: maybe too strong? perhaps just say, it's an alternative?}
% Kollar et al.~\cite{kollarDialog} and Thomason et al.~\cite{thomasonDialog} recognize the
% need for a dialog between a robot and a human in order for the robot to
% understand the human's intentions and to build trust in mutual understanding.
For example, Thomason et al.~\cite{thomasonDialog} demonstrate a system in which
utterances are mapped to $\lambda$-calculus computations and the robot 
fills in the gaps in a simple \textit{action-patient-recipient} pattern, supporting
navigation and delivery.
%
%  whereas \tool's robot actions can be of arbitrary complexity.
%\todo[inline]{ED: how is SHRDLU related to the other works? I would skip the
%sentence about the need for trust. Sounds subjective to me.}
%\todo[inline]{ED: what is an action-patient-recipient pattern? Is there a different
%word for patient?}
%\todo[inline]{IG: it is a type of thematic relation, a concept from linguistics. At least two papers from our related work are using this term}
%Alexandrova et al.\cite{roboFlow} created a flow-based visual programming language, balancing
%intuitiveness and expressivity. 

Formal and logical languages for planning have a long research tradition in AI and formal methods.
Recently, the work by Kress-Gazit et
al.~\cite{hadasTranslatingStructuredEnglish,hadasLTLMop,
hadasProvablyCorrectReactiveControlFromNaturalLanguage} focuses on translating
natural language into linear temporal logic to bridge the gap from users to formal methods
tools.
One project uses a pipeline of general-purpose NLP 
methods~\cite{hadasProvablyCorrectReactiveControlFromNaturalLanguage}, with VerbNet~\cite{schulerVerbnet}
at the core of semantic interpretation. A robot is additionally able
to give an answer to what it is currently doing, based on the natural language
to LTL translation tree, as well as to explain why an action is unrealizable. A
limitation is, however, that the set of actions a robot can perform is still
restricted to implemented semantic behaviours. On the other hand,~\cite{hadasTranslatingStructuredEnglish}
can process any (GR(1)) LTL specification, but the burden is on the human to use
only \emph{structured English}. \tool accomplishes both, with the tradeoff 
that at least some of the users are able to learn the core language.

Tellex et al.~\cite{tellexGrounding} solve the problem of grounding utterances
from the command to objects in space by introducing a hierarchical structure
that connects expressions such as \emph{beside the truck} and \emph{beside the
box}. Paul et al.~\cite{paulGrounding} solve the same problem, but support
abstract expressions such as \emph{first cube in the second row}. This line of
work is connected to the one described in the previous paragraph in the work by
Boteanu et al.~\cite{boteanuVerifiableGrounding}---there the grounding
problem is put in the context of reactive temporal commands. In this line of
work, unlike in \tool, the robot cannot be taught new concepts. On the other hand,
\tool does not support talking about abstract spatial relations between items
in its world. To support this, \tool's core language would need to be modified
(and one could then use the mentioned techniques).

\tool is inspired by and based upon the work on naturalization of formal
languages by Wang et al.~\cite{wangVoxelurn}, which considers
a block world where a user can build various shapes of different
colors. The application of naturalization to a robot world introduces new
challenges: the language contains declarative and unrealizable
commands and dynamic behavior that changes the state of the world.
A similar approach of learning the language from users is presented in~\cite{azariaLia}, but in the context of personal
assistants. 
Iyer et al.~\cite{iyerLearningNeuralSemanticParser} use user's feedback to 
minimize the effort needed for additional annotation of data and iteratively improve their semantic parser 
that translates natural language utterances to SQL queries. 
Beltagy and Quirk~\cite{beltagyIFTT} train a model (an ensemble of a neural network and logistic
regression) that translates a task description from an IFTTT dataset into
executable representations. They show several ways to improve the performance, the
most interesting of which is creating synthetic data by paraphrasing task
descriptions. Work by Lin et al.~\cite{linTelina} has a similar motivation:
starting with questions from popular programming-help websites that describe
programmers' intentions, they devise bash one-liners accomplishing it. 
This kind of work enables semantic parsing from 
less direct instructions, but is not easily adaptable to users interactively giving clues to the 
system about the meaning of the utterance.
None of these papers targeted the robotics domain.

